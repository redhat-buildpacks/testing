= How to build a runtime using buildpack
:icons: font
:revdate: {docdate}
:toc: left
:toclevels: 2
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

https://github.com/redhat-buildpacks/testing/actions/workflows/quarkus.yaml[image:https://github.com/redhat-buildpacks/testing/actions/workflows/quarkus.yaml/badge.svg[]]
https://github.com/redhat-buildpacks/testing/actions/workflows/pack.yaml[image:https://github.com/redhat-buildpacks/testing/actions/workflows/pack.yaml/badge.svg[]]
https://github.com/redhat-buildpacks/testing/actions/workflows/tekton.yaml[image:https://github.com/redhat-buildpacks/testing/actions/workflows/tekton.yaml/badge.svg[]]
https://github.com/redhat-buildpacks/testing/actions/workflows/shipwright.yaml[image:https://github.com/redhat-buildpacks/testing/actions/workflows/shipwright.yaml/badge.svg[]]
https://github.com/redhat-buildpacks/testing/pulse[image:https://img.shields.io/github/commit-activity/m/redhat-buildpacks/testing[]]

== Introduction

The goal of this project is to test/validate different approaches to build a runtime using:

* <<1-quarkus-buildpacks,Quarkus Java Buildpack>>
* <<2-pack-client,Pack>> client
* <<3-tekton,Tekton>> Pipeline
* <<4-rhtap,Red Hat Trusted Application Pipeline (aka RHTAP)>>
* <<5-shipwright,Shipwright>>

== Project Testing Matrix

The following table details the versions of the different tools/images used within the GitHub e2e workflows
like also within the examples presented within this project.

The project currently verifies the following scenario:

- link:.github/workflows/quarkus.yaml[Quarkus HelloWord build using Java Buildpack library]
- link:.github/workflows/pack.yaml[Quarkus HelloWord build using Pack client]
- link:.github/workflows/pack_nodejs.yaml[Node.js Hello using extension and pack]
- link:.github/workflows/tekton.yaml[Quarkus HelloWorld & Tekton Pipeline]
- link:.github/workflows/shipwright.yaml[Quarkus HelloWorld & Shipwright]

[IMPORTANT]
====
The test case covering Tekton https://pipelinesascode.com/[PipelineAsCode] using RHTAP is not implemented as GitHub Workflow !
====


|===
| Tool/Image | Version | Tested | Note

| Lifecycle
| https://github.com/buildpacks/lifecycle/releases/tag/v0.17.0[0.17.0]
| Yes
| -

| Platform
| https://github.com/buildpacks/spec/blob/platform/0.12/platform.md[0.12.0]
| Yes
| -

| Pack cli
| https://github.com/buildpacks/pack/releases/tag/v0.30.0[v0.30.0]
| Yes
| -

| Paketo Builder Tiny (jammy) builder
| https://github.com/paketo-buildpacks/builder-jammy-tiny/releases/tag/v0.0.176[0.0.176]
| Yes
| Package lifecycle 0.17.0

| Paketo community UBI builder
| https://github.com/paketo-community/builder-ubi-base/releases/tag/0.0.1[0.0.1]
| Yes
| Only support Node.js buildpacks.

| Paketo Node.js Extension for ubi
| https://github.com/paketo-community/ubi-nodejs-extension/releases/tag/v0.0.3[0.0.3]
| Yes
| -

| Paketo Java Extension for ubi
| https://github.com/paketo-community/ubi-java-extension[n/a]
| No
| To be tested when released
|===

== 0. Prerequisites

- Docker desktop (or podman) installed and running
- kind CLI installed (>= 0.17)
- Tekton CLI
- Have a kubernetes cluster (kind, minikube, etc)

NOTE: For local tests, we suggest to create a kubernetes `kind` cluster and an unsecure (or secured HTTPS) docker registry using the following bash scripts:

[,bash]
----
curl -s -L "https://raw.githubusercontent.com/snowdrop/k8s-infra/main/kind/kind.sh" | bash -s install
curl -s -L "https://raw.githubusercontent.com/snowdrop/k8s-infra/main/kind/registry.sh" | bash -s install --registry-name kind-registry.local
----

NOTE: Use the command `+... | bash -s -h+` to see the usage

== 1. Quarkus Buildpacks

First, create a Quarkus Hello example using the following maven command.

[,bash]
----
mvn io.quarkus.platform:quarkus-maven-plugin:3.3.2:create \
  -DprojectGroupId=me.snowdrop \
  -DprojectArtifactId=quarkus-hello \
  -DprojectVersion=1.0 \
  -Dextensions='resteasy-reactive,kubernetes,buildpack'
----

To test the project, compile it:
[,bash]
----
cd quarkus-hello
mvn compile quarkus:dev
----

In a separate terminal, curl the HTTP endpoint

[,bash]
----
curl http://localhost:8080/hello
----

To build the container image, do the build using as builder image `paketobuildpacks/builder-jammy-tiny:0.0.176` and pass SOME `+BP_***+` env variables in order to configure properly the Quarkus maven build:

[,bash]
----
mvn package \
 -Dquarkus.container-image.image=kind-registry.local:5000/quarkus-hello:1.0 \
 -Dquarkus.buildpack.jvm-builder-image=paketobuildpacks/builder-jammy-tiny:0.0.176 \
 -Dquarkus.buildpack.builder-env.BP_NATIVE_IMAGE="false" \
 -Dquarkus.buildpack.builder-env.BP_MAVEN_BUILT_ARTIFACT="target/quarkus-app/lib/ target/quarkus-app/*.jar target/quarkus-app/app/ target/quarkus-app/quarkus/" \
 -Dquarkus.buildpack.builder-env.BP_MAVEN_BUILD_ARGUMENTS="package -DskipTests=true -Dmaven.javadoc.skip=true -Dquarkus.package.type=fast-jar" \
 -Dquarkus.container-image.build=true \
 -Dquarkus.container-image.push=true
----

Next, start the container and curl the endpoint

[,bash]
----
docker run -i --rm -p 8080:8080 kind-registry.local:5000/quarkus-hello:1.0
----

== 2. Pack client

To validate this scenario top of the existing quarkus-hello project, we will use the https://buildpacks.io/docs/tools/pack/[pack client].

To build properly the Quarkus container, we must configure the following buildpacks:

* https://github.com/paketo-buildpacks/java[Java Buildpacks]
* https://github.com/paketo-buildpacks/native-image[Native Build]

For that purpose, we use some build-time environment variables `-e` to configure the maven or native build:

[,bash]
----
REGISTRY_HOST="kind-registry.local:5000"
docker rmi ${REGISTRY_HOST}/quarkus-hello:1.0
pack build ${REGISTRY_HOST}/quarkus-hello:1.0 \
     --builder paketobuildpacks/builder-jammy-tiny:0.0.176 \
     -e BP_NATIVE_IMAGE="false" \
     -e BP_MAVEN_BUILT_ARTIFACT="target/quarkus-app/lib/ target/quarkus-app/*.jar target/quarkus-app/app/ target/quarkus-app/quarkus/" \
     -e BP_MAVEN_BUILD_ARGUMENTS="package -DskipTests=true -Dmaven.javadoc.skip=true -Dquarkus.package.type=fast-jar" \
     --volume $HOME/.m2:/home/cnb/.m2:rw \
     #--cache name=quarkus_pack_build \
     --path .
----

____
*Trick*: You can discover the builder images available using the command `pack builder suggest` ;-)
____

Next, start the container and curl the endpoint `+curl http://localhost:8080/hello+`

[,bash]
----
docker run -i --rm -p 8080:8080 kind-registry.local:5000/quarkus-hello:1.0
----

====

== 3. Tekton

See the project documentation for more information: https://tekton.dev/

To use Tekton, it is needed to have a k8s cluster (>= 1.24), a local docker registry

[,bash]
----
curl -s -L "https://raw.githubusercontent.com/snowdrop/k8s-infra/main/kind/kind.sh" | bash -s install
curl -s -L "https://raw.githubusercontent.com/snowdrop/k8s-infra/main/kind/registry.sh" | bash -s install --registry-name kind-registry.local
----

WARNING: Append as suffix to the local registry name `*.local` otherwise buildpacks lifecycle will report this error during analyse phase `+failed to get previous image: connect to repo store 'kind-registry:5000/buildpack/app': Get "https://kind-registry:5000/v2/": http: server gave HTTP response to HTTPS client+`

to install the latest official release (or a specific release)

[,bash]
----
kubectl apply -f https://github.com/tektoncd/pipeline/releases/download/v0.48.0/release.yaml
----

and optionally, you can also install the Tekton dashboard

[,bash]
----
kubectl apply -f https://storage.googleapis.com/tekton-releases/dashboard/latest/release.yaml
----

Expose the dashboard service externally using an ingress route and open the url in your browser: `tekton-ui.127.0.0.1.nip.io`

[,bash]
----
VM_IP=127.0.0.1
kubectl create ingress tekton-ui -n tekton-pipelines --class=nginx --rule="tekton-ui.$VM_IP.nip.io/*=tekton-dashboard:9097"
----

When the platform is ready, you can install the needed Tekton `Tasks`:

[,bash]
----
kubectl apply -f https://raw.githubusercontent.com/tektoncd/catalog/main/task/git-clone/0.9/git-clone.yaml
----

[WARNING]
====
Don't install the buildpacks-phases version 0.2 from the catalog as it is outdated and do not work with lifecycle >= 1.17

[,bash]
----
kubectl apply -f https://raw.githubusercontent.com/redhat-buildpacks/catalog/main/tekton/task/buildpacks-phases/01/buildpacks-phases.yaml
----
====

Set the following variables:

[,bash]
----
IMAGE_NAME=<CONTAINER_REGISTRY>/<ORG>/quarkus-hello
BUILDER_IMAGE=<PAKETO_BUILDER_IMAGE_OR_YOUR_OWN_BUILDER_IMAGE>
----

The https://hub.docker.com/r/paketobuildpacks/builder/tags[paketo builder image] version `0.0.176` https://github.com/paketo-buildpacks/builder-jammy-tiny/releases/tag/v0.0.176[supports]:

[,text]
----
Lifecycle:
  Version: 0.17.0
  Buildpack APIs:
    Deprecated: 0.2, 0.3, 0.4, 0.5, 0.6
    Supported: 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.10
  Platform APIs:
    Deprecated: 0.3, 0.4, 0.5, 0.6
    Supported: 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.10, 0.11, 0.12
----

It is time to create a `Pipelinerun` to build the Quarkus application

[,bash]
----
IMAGE_NAME=kind-registry.local:5000/quarkus-hello

BUILDER_IMAGE=paketobuildpacks/builder-jammy-tiny:0.0.176
CNB_LIFECYCLE_IMAGE=buildpacksio/lifecycle:0.17.0
CNB_BUILD_IMAGE=paketobuildpacks/build-jammy-tiny:latest
CNB_RUN_IMAGE=paketobuildpacks/run-jammy-tiny:latest

kubectl delete PipelineRun/buildpacks-phases
kubectl delete pvc/ws-pvc
cat <<EOF | kubectl apply -f -
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ws-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 500Mi
---
apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  name: buildpacks-phases
  labels:
    app.kubernetes.io/description: "Buildpacks-PipelineRun"
spec:
  pipelineSpec:
    workspaces:
      - name: source-ws
      - name: cache-ws
    tasks:
      - name: fetch-repository
        taskRef:
          name: git-clone
        workspaces:
          - name: output
            workspace: source-ws
        params:
          - name: url
            value: https://github.com/quarkusio/quarkus-quickstarts.git
          - name: deleteExisting
            value: "true"
      - name: buildpacks
        taskRef:
          name: buildpacks-phases
        runAfter:
          - fetch-repository
        workspaces:
          - name: source
            workspace: source-ws
          - name: cache
            workspace: cache-ws
        params:
          - name: APP_IMAGE
            value: ${IMAGE_NAME}
          - name: SOURCE_SUBPATH
            value: getting-started
          - name: CNB_LIFECYCLE_IMAGE
            value:
          - name: CNB_BUILDER_IMAGE
            value: ${BUILDER_IMAGE}
          - name: CNB_BUILD_IMAGE
            value: ${CNB_BUILD_IMAGE}
          - name: CNB_RUN_IMAGE
            value: ${CNB_RUN_IMAGE}
          - name: ENV_VARS
            value:
              - BP_NATIVE_IMAGE=false
              - BP_MAVEN_BUILT_ARTIFACT=target/quarkus-app/lib/ target/quarkus-app/*.jar target/quarkus-app/app/ target/quarkus-app/quarkus/
              - BP_MAVEN_BUILD_ARGUMENTS=package -DskipTests=true -Dmaven.javadoc.skip=true -Dquarkus.package.type=fast-jar
  workspaces:
    - name: source-ws
      subPath: source
      persistentVolumeClaim:
        claimName: ws-pvc
    - name: cache-ws
      subPath: cache
      persistentVolumeClaim:
        claimName: ws-pvc
EOF
----

Follow the execution of the pipeline using the dashboard: http://tekton-ui.127.0.0.1.nip.io/#/namespaces/default/taskruns or using the client: `tkn pipeline logs`

When the task is finished and no error is reported, then launch the container

[,bash]
----
docker run -i --rm -p 8080:8080 kind-registry.local:5000/quarkus-hello
----

== 4. RHTAP

=== Prerequisite

- Have https://redhat-appstudio.github.io/docs.appstudio.io/Documentation/main/getting-started/get-started/[access] to RHTAP - https://console.redhat.com/preview/hac/
- Have kubectl (or oc client) installed on your machine
- Added the kubernetes context of `AppStudio` to your local ~/.kube/config file and been authenticated using https://docs.google.com/document/d/1hFvQDH1H6MGNqTGfcZpyl2h8OIaynP8sokZohCS0Su0/edit#heading=h.bksi3q7km0i[oidc login]
- Add the `AppStudio` GitHub application to your GitHub Org and select it to be used for all the repositories. More information is available https://pipelinesascode.com/docs/install/github_apps/[here].
- (optional). https://tekton.dev/docs/cli/[Install] the Tekton client

=== Env variables

In order to play/execute the commands defined hereafter, it is needed to define some env variables.
Feel free to change them according to your GitHub organisation, tenant namespace, etc

[,bash]
----
GITHUB_ORG_NAME=halkyonio
GITHUB_REPO_TEMPLATE=https://github.com/redhat-buildpacks/catalog.git
GITHUB_REPO_DEMO_NAME=rhtap-buildpack-demo-1
GITHUB_REPO_DEMO_TITLE="RHTAP Buildpack Demo 1"
BRANCH=main
APPLICATION_NAME=$GITHUB_REPO_DEMO_NAME
COMPONENT_NAME="quarkus-hello"
PAC_NAME=$COMPONENT_NAME
PAC_YAML_FILE=".tekton/$GITHUB_REPO_DEMO_NAME-push.yaml"
PAC_EVENT_TYPE="push" # Values could be "push, pull_request"
TENANT_NAMESPACE="<YOUR_TENANT_NAMESPACE>"
REGISTRY_URL=quay.io/redhat-user-workloads/$TENANT_NAMESPACE/$GITHUB_REPO_DEMO_NAME/$COMPONENT_NAME
BUILD_ID=1 # ID used to generate the following kubernetes label's value: test-01 for rhtap.snowdrop.deb/build
----

=== HowTo

To create a new GitHub repository and import the needed files, perform the following actions:

* Git auth
`gh auth login --with-token <YOUR_GITHUB_TOKEN>`

* Create a GitHub repository

[,bash]
----
gh repo delete $GITHUB_ORG_NAME/$GITHUB_REPO_DEMO_NAME --yes
gh repo create \
  -p $GITHUB_REPO_TEMPLATE \
  --clone $GITHUB_ORG_NAME/$GITHUB_REPO_DEMO_NAME \
  --public

rm -rf $GITHUB_REPO_DEMO_NAME
git clone git@github.com:$GITHUB_ORG_NAME/$GITHUB_REPO_DEMO_NAME
cd $GITHUB_REPO_DEMO_NAME
----

* Test locally the quarkus project and access using curl (or httpie) the endpoints (optional)

[,bash]
----
mvn clean compile; mvn quarkus:dev

# In a separate terminal, execute such httpie (or curl) commands
http :8080/hello
http :8080/hello/greeting/charles
----

* Get the RHTAP pipelineRun and rename the template file

[,bash]
----
mkdir .tekton
cp tekton/pipelinerun/rhtap/pipelinerun-buildpacks-template.yaml .tekton/$GITHUB_REPO_DEMO_NAME-push.yaml
git add .tekton/$GITHUB_REPO_DEMO_NAME-push.yaml
git commit -asm "Add the PipelineRun"
----

* Customize the RHTAP PipelineRun

[,bash]
----
sed -i.bak "s/#APPLICATION_NAME#/$APPLICATION_NAME/g" $PAC_YAML_FILE
sed -i.bak "s/#COMPONENT_NAME#/$COMPONENT_NAME/g" $PAC_YAML_FILE
sed -i.bak "s/#PAC_NAME#/$PAC_NAME/g" $PAC_YAML_FILE
sed -i.bak "s/#TENANT_NAMESPACE#/$TENANT_NAMESPACE/g" $PAC_YAML_FILE
sed -i.bak "s|#REGISTRY_URL#|$REGISTRY_URL|g" $PAC_YAML_FILE
sed -i.bak "s|#BUILD_ID#|$BUILD_ID|g" $PAC_YAML_FILE
sed -i.bak "s|#EVENT_TYPE#|$PAC_EVENT_TYPE|g" $PAC_YAML_FILE
rm $PAC_YAML_FILE.bak
git commit -sm "Add the tekton push file" .tekton/$GITHUB_REPO_DEMO_NAME-push.yaml
git push
----

* Create the following Application CR and Component CR

[,bash]
----
cat <<EOF | kubectl apply -n $TENANT_NAMESPACE -f -
---
apiVersion: appstudio.redhat.com/v1alpha1
kind: Application
metadata:
  name: $GITHUB_REPO_DEMO_NAME
spec:
  appModelRepository:
    url: ""
  displayName: $GITHUB_REPO_DEMO_NAME
  gitOpsRepository:
    url: ""
---
apiVersion: appstudio.redhat.com/v1alpha1
kind: Component
metadata:
  annotations:
    appstudio.openshift.io/pac-provision: request
    image.redhat.com/generate: '{"visibility":"public"}'
  name: $COMPONENT_NAME
spec:
  application: $GITHUB_REPO_DEMO_NAME
  componentName: $COMPONENT_NAME
  replicas: 1
  resources:
    requests:
      cpu: 10m
      memory: 100Mi
  source:
    git:
      context: ./
      devfileUrl: https://raw.githubusercontent.com/devfile-samples/devfile-sample-code-with-quarkus/main/devfile.yaml
      #dockerfileUrl: https://raw.githubusercontent.com/devfile-samples/devfile-sample-code-with-quarkus/main/src/main/docker/Dockerfile.jvm.staged
      revision: main
      url: https://github.com/halkyonio/$GITHUB_REPO_DEMO_NAME.git
  targetPort: 8080
EOF
----

* Check resources created

[,bash]
----
for entity in pods deployments routes services taskruns pipelineruns applications components snapshotenvironmentbinding.appstudio.redhat.com componentdetectionquery.appstudio.redhat.com; do count=$(kubectl -n $TENANT_NAMESPACE get "$entity" -o name | wc -l); echo "$count $entity"; done | sort -n
----

* Push a commit top of the github repository created, open the `activity` tab of the RHTAP console and you should see that
  a custom build has been started for pull and push :-)

* Alternatively, Import it as documented here: https://redhat-appstudio.github.io/docs.appstudio.io/Documentation/main/how-to-guides/Import-code/proc_importing_code/

* Cleaning

[,bash]
----
kubectl delete application/$GITHUB_REPO_DEMO_NAME
----

=== Todo

- Try to make a test using our own quay.io credentials and repository using REGISTRY_URL=quay.io/$GITHUB_ORG_NAME

=== Issue

==== Full image path not supported

The lifecycle component and most probably google container library (used by lifecycle to access the registry) do not support such advanced feature: https://kubernetes.io/docs/concepts/containers/images/#kubelet-credential-provider
The consequence is that if several secrets are attached to the `appstudio-pipeline` service account and subsequently by the pod running lifecycle, then
lifecycle, at the analysis step, will raise an issue if it doesn't get as first entry of the `auths:` config file (from mounted secrets) the full image path matching the image name declared
as output image.

To work around the issue of the full image path not supported by lifecycle (and google-containr), path the secret

[,bash]
----
CFG=$(cat <<EOF
{"auths":{"quay.io":{"auth":"cmVkaG...aRkFGNTQ="}}}
EOF
)

SECRET_NAME=$COMPONENT_NAME
TENANT_NAMESPACE="cmoullia-tenant"
PATCH_STRING="[{'op': 'replace', 'path': '/data/.dockerconfigjson', 'value': '$BASE64_ENCODED_VALUE'}]"

kubectl get secret $SECRET_NAME -n $TENANT_NAMESPACE$$ -o json | jq --arg new_val "$(echo -n $CFG | base64)" '.data[".dockerconfigjson"]=$new_val' | kubectl apply -f -
----


== 5. Shipwright

See the project documentation for more information: https://github.com/shipwright-io/build

To use shipwright, it is needed to have a k8s cluster, local docker registry and tekton installed (v0.41.+)

[,bash]
----
curl -s -L "https://raw.githubusercontent.com/snowdrop/k8s-infra/main/kind/kind.sh" | bash -s install
curl -s -L "https://raw.githubusercontent.com/snowdrop/k8s-infra/main/kind/registry.sh" | bash -s install --registry-name kind-registry.local
kubectl apply -f https://storage.googleapis.com/tekton-releases/pipeline/previous/v0.48.0/release.yaml
----

Next, deploy the latest release of shipwright

[,bash]
----
kubectl apply -f https://github.com/shipwright-io/build/releases/download/v0.11.0/release.yaml
----

Next, install the `Buildpacks BuildStrategy` using the following command:

[,bash]
----
kubectl delete -f k8s/shipwright/unsecured/clusterbuildstrategy.yml
kubectl apply -f k8s/shipwright/unsecured/clusterbuildstrategy.yml
----

As the Paketo builder images are quite big, we suggest to relocate them to the kind registry using the https://carvel.dev/imgpkg/docs/v0.36.x/install/[imgpkg] tool:

[,bash]
----
BUILDER_VERSION=0.1.361-tiny
imgpkg copy -i docker.io/paketobuildpacks/builder:$BUILDER_VERSION --to-tar ./k8s/builder-$BUILDER_VERSION.tar

imgpkg copy \
  --tar ./k8s/builder-$BUILDER_VERSION.tar \
  --to-repo kind-registry.local:5000/paketobuildpacks/builder
----

[TIP]
====
Useful blog post to customize paketo build: https://blog.dahanne.net/2021/02/06/customizing-cloud-native-buildpacks-practical-examples/

Create the `Build` CR using as source the Quarkus Getting started repository:
====

[,bash]
----
kubectl delete -f k8s/shipwright/unsecured/build.yml
kubectl apply -f k8s/shipwright/unsecured/build.yml
----

To view the Build which you just created:

[,bash]
----
kubectl get build
NAME                      REGISTERED   REASON      BUILDSTRATEGYKIND      BUILDSTRATEGYNAME   CREATIONTIME
buildpack-quarkus-build   True         Succeeded   ClusterBuildStrategy   buildpacks          6s
----

Trigger a `BuildRun`:

[,bash]
----
kubectl delete -f k8s/shipwright/unsecured/pvc.yml
kubectl delete buildrun -lbuild.shipwright.io/name=buildpack-quarkus-build
kubectl create -f k8s/shipwright/unsecured/pvc.yml
kubectl create -f k8s/shipwright/unsecured/buildrun.yml
----

Wait until your BuildRun is completed, and then you can view it as follows:

[,bash]
----
kubectl get buildruns
NAME                              SUCCEEDED   REASON      STARTTIME   COMPLETIONTIME
buildpack-quarkus-buildrun-vp2gb   True        Succeeded   2m22s       9s
----

When the task is finished and no error is reported, then launch the container

[,bash]
----
docker run -i --rm -p 8080:8080 kind-registry.local:5000/quarkus-hello
----

=== Secured container registry

If you prefer to use a secure registry, then some additional steps are needed such as

Install a secured container registry

[,bash]
----
curl -s -L "https://raw.githubusercontent.com/snowdrop/k8s-infra/main/kind/kind.sh" | bash -s install
curl -s -L "https://raw.githubusercontent.com/snowdrop/k8s-infra/main/kind/registry.sh" | bash -s install --registry-name kind-registry.local --secure-registry --registry-name=kind-registry.local
----

NOTE: To install a secured (HTTPS and authentication) docker registry, pass the parameter: --secure-registry

Generate a docker-registry secret

NOTE: This secret will be used by the serviceAccount of the build's pod to access the container registry

[,bash]
----
REGISTRY_HOST="kind-registry.local:5000" REGISTRY_USER=admin REGISTRY_PASSWORD=snowdrop
kubectl create ns demo
kubectl create secret docker-registry registry-creds \
  --docker-server="${REGISTRY_HOST}" \
  --docker-username="${REGISTRY_USER}" \
  --docker-password="${REGISTRY_PASSWORD}"
----

Create a serviceAccount that the platform will use to perform the build and able to be authenticated using the
secret's credentials with the registry

[,bash]
----
kubectl delete -f k8s/shipwright/secured/sa.yml
kubectl apply -f k8s/shipwright/secured/sa.yml
----

Add the selfsigned certificate to a configMap. It will be mounted as a volume to set the env var `SSL_CERT_DIR` used by the go-containerregistry lib (of lifecycle)
to access the registry using the HTTPS/TLS protocol.

[,bash]
----
kubectl delete configmap certificate-registry
kubectl create configmap certificate-registry \
  --from-file=kind-registry.crt=$HOME/.registry/certs/kind-registry.local/client.crt
----

Deploy the `ClusterBuildStrategy` file from the secured folder as it includes a new volume to mount the certificate

[,yaml]
----
apiVersion: shipwright.io/v1alpha1
kind: ClusterBuildStrategy
metadata:
  name: buildpacks
spec:
  volumes:
    - name: certificate-registry
      configMap:
        name: certificate-registry
...
parameters:
  - name: certificate-path
    description: Path to self signed certificate(s)
...
- name: export
  image: $(params.CNB_LIFECYCLE_IMAGE)
  imagePullPolicy: Always
...
volumeMounts:
- mountPath: /selfsigned-certificates
  name: certificate-registry
  readOnly: true
----

=== All steps

Setup first the kind cluster and docker registry

[,bash]
----
curl -s -L "https://raw.githubusercontent.com/snowdrop/k8s-infra/main/kind/kind.sh" | bash -s install
curl -s -L "https://raw.githubusercontent.com/snowdrop/k8s-infra/main/kind/registry.sh" | bash -s install
----

NOTE: To install a secured (HTTPS and authentication) docker registry, pass the parameter: --secure-registry

Next, install Tekton and Shipwright

[,bash]
----
kubectl apply -f https://storage.googleapis.com/tekton-releases/pipeline/previous/v0.48.0/release.yaml
kubectl apply -f https://github.com/shipwright-io/build/releases/download/v0.11.0/release.yaml
----

And finally, deploy the resources using either an `unsecured` or `secured` container registry

. Unsecured

Upload the paketo builder tar image `builder-base.tar` or `builder-full.tar`

[,bash]
----
BUILDER_VERSION=0.1.361-tiny
imgpkg copy --registry-insecure \
  --tar ./k8s/builder-$BUILDER_VERSION.tar \
  --to-repo kind-registry.local:5000/paketobuildpacks/builder
----

And deploy the needed resources

[,bash]
----
DIR="unsecured"
kubectl delete buildrun -lbuild.shipwright.io/name=buildpack-quarkus-build
kubectl delete -f k8s/shipwright/${DIR}/build.yml
kubectl delete -f k8s/shipwright/${DIR}/clusterbuildstrategy.yml
kubectl delete -f k8s/shipwright/${DIR}/pvc.yml

kubectl create -f k8s/shipwright/${DIR}/pvc.yml
kubectl apply  -f k8s/shipwright/${DIR}/clusterbuildstrategy.yml
kubectl apply  -f k8s/shipwright/${DIR}/build.yml
kubectl create -f k8s/shipwright/${DIR}/buildrun.yml
----

. Secured

Upload the paketo builder tar image `builder-base.tar` or `builder-full.tar`

[,bash]
----
BUILDER_VERSION=0.1.361-tiny
imgpkg copy --registry-ca-cert-path ~/.registry/certs/kind-registry.local/client.crt \
  --registry-username admin --registry-password snowdrop \
  --tar ./k8s/builder-$BUILDER_VERSION.tar \
  --to-repo kind-registry.local:5000/paketobuildpacks/builder
----

And deploy the needed resources

[,bash]
----
DIR="secured"
kubectl create configmap certificate-registry \
  --from-file=kind-registry.crt=./k8s/shipwright/${DIR}/binding/ca-certificates/kind-registry.local.crt

REGISTRY_HOST="kind-registry.local:5000" REGISTRY_USER=admin REGISTRY_PASSWORD=snowdrop
kubectl create secret docker-registry registry-creds \
  --docker-server="${REGISTRY_HOST}" \
  --docker-username="${REGISTRY_USER}" \
  --docker-password="${REGISTRY_PASSWORD}"

kubectl apply  -f k8s/shipwright/${DIR}/sa.yml
kubectl apply  -f k8s/shipwright/${DIR}/clusterbuildstrategy.yml
kubectl apply  -f k8s/shipwright/${DIR}/build.yml
kubectl create -f k8s/shipwright/${DIR}/buildrun.yml
----

To clean up

[,bash]
----
DIR="unsecured"
kubectl delete secret registry-creds
kubectl delete buildrun -lbuild.shipwright.io/name=buildpack-quarkus-build
kubectl delete -f k8s/shipwright/${DIR}/build.yml
kubectl delete -f k8s/shipwright/${DIR}/clusterbuildstrategy.yml
kubectl delete -f k8s/shipwright/${DIR}/pvc.yml
----
